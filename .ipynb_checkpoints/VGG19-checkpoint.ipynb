{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REFERÊNCIAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IDEIA ORIGINAL: <br/>\n",
    "Adam Rosembrock <br/>\n",
    "pyimagesearch.com - \n",
    "https://www.pyimagesearch.com/2020/03/16/detecting-covid-19-in-x-ray-images-with-keras-tensorflow-and-deep-learning/\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ATENÇÃO\n",
    "\n",
    "Os métodos e técnicas usados neste vídeo são apenas para fins educacionais. Esse não é um estudo cientificamente rigoroso, nem será publicado em uma revista científica´."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AGENDA\n",
    "\n",
    "Dentro do tutorial de hoje, você aprenderá como:\n",
    "\n",
    "- Abrir uma base de imagens de raio-X  (open data) de pacientes com resultado POSITIVO para COVID-19 e imagens de pacientes com resultado NEGATIVO.\n",
    "\n",
    "\n",
    "- Dividir o dataset de imagens em conjunto de teste e conjunto de treino \n",
    "\n",
    "\n",
    "- Aplicar a técnica de aumento de dados (Data Augmentation)\n",
    "\n",
    "\n",
    "\n",
    "- Aplicar a técnica de transferência de inteligência entre redes neurais (Transfer Learning)\n",
    "\n",
    "\n",
    "- Treinar uma Rede Neural Convolucional com o Tensorflow/Keras para detectar automaticamente o COVID-19 em imagens de raios-X \n",
    "\n",
    "\n",
    "- Avaliar os resultados sob uma perspectiva educacional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## importações de bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from os import listdir\n",
    "from os.path import isdir\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando uma imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_image(filename):\n",
    "    # load image from file\n",
    "    image = Image.open(filename)\n",
    "    # convert to RGB, if needed\n",
    "    image = image.convert('RGB')\n",
    "    image = image.resize((150,150))\n",
    "    # convert to array\n",
    "    return np.asarray(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando uma classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_classes(diretorio, classe, imagens, labels):\n",
    "    # iterando arquivos\n",
    "\n",
    "    for filename in listdir(diretorio):\n",
    "\n",
    "        path = diretorio + filename\n",
    "\n",
    "        try:\n",
    "            imagens.append(select_image(path))\n",
    "            labels.append(classe)\n",
    "        except:\n",
    "            print(\"Erro ao ler imagem {}\".format(path))\n",
    "\n",
    "    return imagens, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecionando Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_data_set(diretorio):\n",
    "\n",
    "    imagens = list()\n",
    "    labels = list()\n",
    "\n",
    "    for subdir in listdir(diretorio):\n",
    "        # path\n",
    "        path = diretorio + subdir + '/'\n",
    "\n",
    "        if not isdir(path):\n",
    "            continue\n",
    "        imagens, labels = load_classes(path, subdir, imagens, labels)\n",
    "\n",
    "    return imagens, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando dataset Covid-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['normal', 'normal', 'normal', 'normal', 'normal', 'normal',\n",
       "       'normal', 'normal', 'normal', 'normal', 'normal', 'normal',\n",
       "       'normal', 'normal', 'normal', 'normal', 'normal', 'normal',\n",
       "       'normal', 'normal', 'normal', 'normal', 'normal', 'normal',\n",
       "       'normal', 'normal', 'normal', 'normal', 'normal', 'normal',\n",
       "       'normal', 'normal', 'normal', 'normal', 'normal', 'normal',\n",
       "       'normal', 'normal', 'normal', 'normal', 'normal', 'normal',\n",
       "       'normal', 'normal', 'normal', 'normal', 'normal', 'normal',\n",
       "       'normal', 'normal', 'normal', 'normal', 'normal', 'normal',\n",
       "       'normal', 'normal', 'normal', 'normal', 'normal', 'normal',\n",
       "       'normal', 'normal', 'normal', 'normal', 'covid-19', 'covid-19',\n",
       "       'covid-19', 'covid-19', 'covid-19', 'covid-19', 'covid-19',\n",
       "       'covid-19', 'covid-19', 'covid-19', 'covid-19', 'covid-19',\n",
       "       'covid-19', 'covid-19', 'covid-19', 'covid-19', 'covid-19',\n",
       "       'covid-19', 'covid-19', 'covid-19', 'covid-19', 'covid-19',\n",
       "       'covid-19', 'covid-19', 'covid-19', 'covid-19', 'covid-19',\n",
       "       'covid-19', 'covid-19', 'covid-19', 'covid-19', 'covid-19',\n",
       "       'covid-19', 'covid-19', 'covid-19', 'covid-19', 'covid-19',\n",
       "       'covid-19', 'covid-19', 'covid-19', 'covid-19', 'covid-19',\n",
       "       'covid-19', 'covid-19', 'covid-19', 'covid-19', 'covid-19',\n",
       "       'covid-19', 'covid-19', 'covid-19', 'covid-19', 'covid-19',\n",
       "       'covid-19', 'covid-19', 'covid-19', 'covid-19', 'covid-19',\n",
       "       'covid-19', 'covid-19', 'covid-19', 'covid-19', 'covid-19',\n",
       "       'covid-19', 'covid-19', 'pneumonia', 'pneumonia', 'pneumonia',\n",
       "       'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia',\n",
       "       'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia',\n",
       "       'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia',\n",
       "       'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia',\n",
       "       'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia',\n",
       "       'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia',\n",
       "       'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia',\n",
       "       'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia',\n",
       "       'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia',\n",
       "       'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia',\n",
       "       'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia',\n",
       "       'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia', 'pneumonia',\n",
       "       'pneumonia'], dtype='<U9')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_dataset = \"/home/labcfd/Desktop/github/covid19XRayClassification/dataset/\"\n",
    "imagens, labels  = select_data_set(covid_dataset)\n",
    "imagens = np.array(imagens) / 255.0  ## convertendo de lista para array\n",
    "labels = np.array(labels)  ## convertendo de lista para array\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratando classes - Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lb = LabelBinarizer()\n",
    "# labels = lb.fit_transform(labels)\n",
    "# labels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "labels = encoder.fit_transform(labels)\n",
    "labels = to_categorical(labels)\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo hyperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size   = 32\n",
    "input_shape  = (150, 150, 3)\n",
    "random_state = 42\n",
    "alpha        = 1e-5\n",
    "epoch        = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CALLBACKS\n",
    "\n",
    "Callback são classes que auxiliam o treinamento do modelo usando o Keras. As classes que usaremos são:\n",
    "\n",
    "- ModelCheckpoint\n",
    "- ReduceLROnPlateau\n",
    "- EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ModelCheckpoint\n",
    "\n",
    "ModelCheckpoint nos ajudará a salvar o modelo para cada época, para que possamos treinar nosso modelo e não nos preocuparmos com possíveis problemas que possam acontecer, como travamento da máquina.\n",
    "\n",
    "- **filepath**: onde será salvo o modelo\n",
    "- **monitor**: métrica a ser monitorada\n",
    "- **verbose**: (1) mostra na barra de progresso (0) não\n",
    "- **save_best_only**: Salvar somente o melhor modelo\n",
    "- **mode**: como vamos monitorar o 'val_acc' o valor aqui vai ser 'max'. Queremos a máxima acurácia.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"transferlearning_weights.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ReduceLROnPlateau\n",
    "\n",
    "Nos auxiliara a reduzir a taxa de aprendizado pelo fator (factor) caso não ocorra a mudança no loss.\n",
    "\n",
    "- **monitor**: métrica a ser monitorada\n",
    "- **factor**: fator de redução caso estejamos em um plator\n",
    "- **min_delta**: valor mínimo da perda\n",
    "- **patience**: só altere pelo fator após se repitir por 'patience' vezes.\n",
    "- **verbose**: (1) mostra na barra de progresso (0) não\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.1, min_delta=alpha, patience=5, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Array de Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [checkpoint, lr_reduce]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Particionando dataset em teste e treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX, testX, trainY, testY) = train_test_split(imagens, labels, test_size=0.20, stratify=labels, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA AUGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        zoom_range=0.2)\n",
    "\n",
    "train_datagen.fit(trainX)\n",
    "\n",
    "data_aug = train_datagen.flow(trainX, trainY, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRANSFER LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base = VGG19(weights='imagenet', include_top=False, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 150, 150, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 20,024,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retreinando parte da VGG19\n",
    "\n",
    "\n",
    "explicar aqui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.trainable = True\n",
    "set_trainable = False\n",
    "\n",
    "for layer in conv_base.layers:\n",
    "  if layer.name == 'block5_conv1':\n",
    "    set_trainable = True\n",
    "  if set_trainable:\n",
    "    layer.trainable = True\n",
    "  else:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 150, 150, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 9,439,232\n",
      "Non-trainable params: 10,585,152\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRIANDO O MODELO COM A VGG19 COMO BASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0329 19:24:40.977962 140320653379392 nn_ops.py:4372] Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(0.6))\n",
    "model.add(layers.Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg19 (Model)                (None, 4, 4, 512)         20024384  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 20,092,483\n",
      "Trainable params: 9,506,307\n",
      "Non-trainable params: 10,586,176\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMPILANDO O MODELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TREINANDO O MODELO\n",
    "\n",
    "***Obs: não treinar na hora da live***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0329 19:25:01.413692 140320653379392 deprecation.py:323] From <ipython-input-118-157b40edf3b9>:7: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "W0329 19:25:02.053513 140320653379392 data_adapter.py:1091] sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "W0329 19:25:02.446273 140320653379392 nn_ops.py:4372] Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 4 steps, validate on 39 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0329 19:25:02.704678 140320653379392 nn_ops.py:4372] Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/4 [=====================>........] - ETA: 2s - loss: 0.5946 - acc: 0.6966\n",
      "Epoch 00001: val_acc improved from -inf to 0.56250, saving model to transferlearning_weights.hdf5\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.5871 - acc: 0.7107 - val_loss: 4.3225 - val_acc: 0.5625\n",
      "Epoch 2/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.3805 - acc: 0.8438\n",
      "Epoch 00002: val_acc did not improve from 0.56250\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.3890 - acc: 0.8490 - val_loss: 5.3170 - val_acc: 0.5625\n",
      "Epoch 3/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.3684 - acc: 0.8502\n",
      "Epoch 00003: val_acc did not improve from 0.56250\n",
      "4/4 [==============================] - 18s 4s/step - loss: 0.3301 - acc: 0.8733 - val_loss: 5.4125 - val_acc: 0.5625\n",
      "Epoch 4/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.2053 - acc: 0.9326\n",
      "Epoch 00004: val_acc did not improve from 0.56250\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.2232 - acc: 0.9146 - val_loss: 5.5056 - val_acc: 0.5625\n",
      "Epoch 5/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.1874 - acc: 0.9401\n",
      "Epoch 00005: val_acc did not improve from 0.56250\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.1776 - acc: 0.9449 - val_loss: 5.5056 - val_acc: 0.5625\n",
      "Epoch 6/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.1385 - acc: 0.9700\n",
      "Epoch 00006: val_acc did not improve from 0.56250\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "4/4 [==============================] - 18s 4s/step - loss: 0.1284 - acc: 0.9669 - val_loss: 5.3739 - val_acc: 0.5625\n",
      "Epoch 7/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0984 - acc: 0.9588\n",
      "Epoch 00007: val_acc did not improve from 0.56250\n",
      "4/4 [==============================] - 18s 4s/step - loss: 0.1004 - acc: 0.9559 - val_loss: 5.0625 - val_acc: 0.5625\n",
      "Epoch 8/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0859 - acc: 0.9688\n",
      "Epoch 00008: val_acc did not improve from 0.56250\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0760 - acc: 0.9752 - val_loss: 5.0356 - val_acc: 0.5625\n",
      "Epoch 9/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0849 - acc: 0.9738\n",
      "Epoch 00009: val_acc did not improve from 0.56250\n",
      "4/4 [==============================] - 18s 4s/step - loss: 0.0994 - acc: 0.9642 - val_loss: 4.9613 - val_acc: 0.5625\n",
      "Epoch 10/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0672 - acc: 0.9861\n",
      "Epoch 00010: val_acc did not improve from 0.56250\n",
      "4/4 [==============================] - 18s 4s/step - loss: 0.0564 - acc: 0.9890 - val_loss: 4.7112 - val_acc: 0.5625\n",
      "Epoch 11/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.1177 - acc: 0.9618\n",
      "Epoch 00011: val_acc did not improve from 0.56250\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "4/4 [==============================] - 18s 4s/step - loss: 0.0976 - acc: 0.9697 - val_loss: 4.4640 - val_acc: 0.5625\n",
      "Epoch 12/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0697 - acc: 0.9826\n",
      "Epoch 00012: val_acc did not improve from 0.56250\n",
      "4/4 [==============================] - 18s 4s/step - loss: 0.0600 - acc: 0.9862 - val_loss: 4.2626 - val_acc: 0.5625\n",
      "Epoch 13/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0494 - acc: 0.9925\n",
      "Epoch 00013: val_acc did not improve from 0.56250\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0513 - acc: 0.9890 - val_loss: 4.0544 - val_acc: 0.5625\n",
      "Epoch 14/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0394 - acc: 0.9925\n",
      "Epoch 00014: val_acc did not improve from 0.56250\n",
      "4/4 [==============================] - 18s 4s/step - loss: 0.0469 - acc: 0.9835 - val_loss: 3.8368 - val_acc: 0.5625\n",
      "Epoch 15/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0816 - acc: 0.9700\n",
      "Epoch 00015: val_acc did not improve from 0.56250\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.0692 - acc: 0.9780 - val_loss: 3.6031 - val_acc: 0.5625\n",
      "Epoch 16/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0732 - acc: 0.9861\n",
      "Epoch 00016: val_acc did not improve from 0.56250\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "4/4 [==============================] - 19s 5s/step - loss: 0.0751 - acc: 0.9792 - val_loss: 3.3712 - val_acc: 0.5625\n",
      "Epoch 17/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0659 - acc: 0.9775\n",
      "Epoch 00017: val_acc did not improve from 0.56250\n",
      "4/4 [==============================] - 18s 5s/step - loss: 0.0680 - acc: 0.9780 - val_loss: 3.1509 - val_acc: 0.5625\n",
      "Epoch 18/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0694 - acc: 0.9775\n",
      "Epoch 00018: val_acc did not improve from 0.56250\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0694 - acc: 0.9780 - val_loss: 2.9425 - val_acc: 0.5625\n",
      "Epoch 19/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0427 - acc: 0.9850\n",
      "Epoch 00019: val_acc did not improve from 0.56250\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0520 - acc: 0.9835 - val_loss: 2.7520 - val_acc: 0.5625\n",
      "Epoch 20/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0652 - acc: 0.9738\n",
      "Epoch 00020: val_acc did not improve from 0.56250\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0569 - acc: 0.9807 - val_loss: 2.5609 - val_acc: 0.5625\n",
      "Epoch 21/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0657 - acc: 0.9775\n",
      "Epoch 00021: val_acc did not improve from 0.56250\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0825 - acc: 0.9725 - val_loss: 2.3962 - val_acc: 0.5625\n",
      "Epoch 22/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0761 - acc: 0.9738\n",
      "Epoch 00022: val_acc improved from 0.56250 to 0.60417, saving model to transferlearning_weights.hdf5\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0717 - acc: 0.9725 - val_loss: 2.2392 - val_acc: 0.6042\n",
      "Epoch 23/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0856 - acc: 0.9653\n",
      "Epoch 00023: val_acc did not improve from 0.60417\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0708 - acc: 0.9740 - val_loss: 2.0933 - val_acc: 0.6042\n",
      "Epoch 24/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0695 - acc: 0.9775\n",
      "Epoch 00024: val_acc improved from 0.60417 to 0.62500, saving model to transferlearning_weights.hdf5\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0702 - acc: 0.9780 - val_loss: 1.9534 - val_acc: 0.6250\n",
      "Epoch 25/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0731 - acc: 0.9722\n",
      "Epoch 00025: val_acc did not improve from 0.62500\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0743 - acc: 0.9740 - val_loss: 1.8131 - val_acc: 0.6250\n",
      "Epoch 26/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0665 - acc: 0.9722\n",
      "Epoch 00026: val_acc did not improve from 0.62500\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0589 - acc: 0.9780 - val_loss: 1.6931 - val_acc: 0.6250\n",
      "Epoch 27/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0579 - acc: 0.9850\n",
      "Epoch 00027: val_acc did not improve from 0.62500\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0725 - acc: 0.9752 - val_loss: 1.5904 - val_acc: 0.6250\n",
      "Epoch 28/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0481 - acc: 0.9850\n",
      "Epoch 00028: val_acc did not improve from 0.62500\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0461 - acc: 0.9890 - val_loss: 1.4826 - val_acc: 0.6250\n",
      "Epoch 29/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0802 - acc: 0.9722\n",
      "Epoch 00029: val_acc improved from 0.62500 to 0.64583, saving model to transferlearning_weights.hdf5\n",
      "4/4 [==============================] - 18s 5s/step - loss: 0.0769 - acc: 0.9740 - val_loss: 1.3822 - val_acc: 0.6458\n",
      "Epoch 30/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0783 - acc: 0.9688\n",
      "Epoch 00030: val_acc did not improve from 0.64583\n",
      "4/4 [==============================] - 18s 4s/step - loss: 0.0831 - acc: 0.9661 - val_loss: 1.2869 - val_acc: 0.6458\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0332 - acc: 1.0000\n",
      "Epoch 00031: val_acc improved from 0.64583 to 0.66667, saving model to transferlearning_weights.hdf5\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0376 - acc: 0.9972 - val_loss: 1.2087 - val_acc: 0.6667\n",
      "Epoch 32/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0416 - acc: 0.9925\n",
      "Epoch 00032: val_acc improved from 0.66667 to 0.70833, saving model to transferlearning_weights.hdf5\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0499 - acc: 0.9890 - val_loss: 1.1401 - val_acc: 0.7083\n",
      "Epoch 33/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0469 - acc: 0.9925\n",
      "Epoch 00033: val_acc did not improve from 0.70833\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0569 - acc: 0.9890 - val_loss: 1.0752 - val_acc: 0.7083\n",
      "Epoch 34/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0533 - acc: 0.9850\n",
      "Epoch 00034: val_acc did not improve from 0.70833\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0681 - acc: 0.9725 - val_loss: 1.0150 - val_acc: 0.7083\n",
      "Epoch 35/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0907 - acc: 0.9618\n",
      "Epoch 00035: val_acc did not improve from 0.70833\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0727 - acc: 0.9697 - val_loss: 0.9610 - val_acc: 0.7083\n",
      "Epoch 36/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0519 - acc: 0.9813\n",
      "Epoch 00036: val_acc did not improve from 0.70833\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0625 - acc: 0.9752 - val_loss: 0.9126 - val_acc: 0.7083\n",
      "Epoch 37/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0670 - acc: 0.9775\n",
      "Epoch 00037: val_acc improved from 0.70833 to 0.72917, saving model to transferlearning_weights.hdf5\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0712 - acc: 0.9725 - val_loss: 0.8620 - val_acc: 0.7292\n",
      "Epoch 38/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0935 - acc: 0.9653\n",
      "Epoch 00038: val_acc improved from 0.72917 to 0.76042, saving model to transferlearning_weights.hdf5\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0766 - acc: 0.9725 - val_loss: 0.8201 - val_acc: 0.7604\n",
      "Epoch 39/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0550 - acc: 0.9792\n",
      "Epoch 00039: val_acc did not improve from 0.76042\n",
      "4/4 [==============================] - 18s 4s/step - loss: 0.0681 - acc: 0.9792 - val_loss: 0.7731 - val_acc: 0.7604\n",
      "Epoch 40/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0475 - acc: 0.9813\n",
      "Epoch 00040: val_acc improved from 0.76042 to 0.78125, saving model to transferlearning_weights.hdf5\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0487 - acc: 0.9807 - val_loss: 0.7307 - val_acc: 0.7812\n",
      "Epoch 41/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0444 - acc: 0.9888\n",
      "Epoch 00041: val_acc improved from 0.78125 to 0.79167, saving model to transferlearning_weights.hdf5\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0540 - acc: 0.9807 - val_loss: 0.6946 - val_acc: 0.7917\n",
      "Epoch 42/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0455 - acc: 0.9925\n",
      "Epoch 00042: val_acc did not improve from 0.79167\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0556 - acc: 0.9862 - val_loss: 0.6596 - val_acc: 0.7917\n",
      "Epoch 43/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.1012 - acc: 0.9700\n",
      "Epoch 00043: val_acc did not improve from 0.79167\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0996 - acc: 0.9669 - val_loss: 0.6293 - val_acc: 0.7917\n",
      "Epoch 44/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0814 - acc: 0.9738\n",
      "Epoch 00044: val_acc did not improve from 0.79167\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0728 - acc: 0.9780 - val_loss: 0.6014 - val_acc: 0.7917\n",
      "Epoch 45/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0437 - acc: 0.9850\n",
      "Epoch 00045: val_acc did not improve from 0.79167\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0473 - acc: 0.9835 - val_loss: 0.5737 - val_acc: 0.7917\n",
      "Epoch 46/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0594 - acc: 0.9850\n",
      "Epoch 00046: val_acc did not improve from 0.79167\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0630 - acc: 0.9835 - val_loss: 0.5508 - val_acc: 0.7917\n",
      "Epoch 47/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0469 - acc: 0.9931\n",
      "Epoch 00047: val_acc improved from 0.79167 to 0.81250, saving model to transferlearning_weights.hdf5\n",
      "4/4 [==============================] - 18s 4s/step - loss: 0.0551 - acc: 0.9896 - val_loss: 0.5231 - val_acc: 0.8125\n",
      "Epoch 48/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0536 - acc: 0.9738\n",
      "Epoch 00048: val_acc did not improve from 0.81250\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0594 - acc: 0.9780 - val_loss: 0.5011 - val_acc: 0.8125\n",
      "Epoch 49/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0618 - acc: 0.9775\n",
      "Epoch 00049: val_acc did not improve from 0.81250\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0678 - acc: 0.9780 - val_loss: 0.4833 - val_acc: 0.8125\n",
      "Epoch 50/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0811 - acc: 0.9625\n",
      "Epoch 00050: val_acc did not improve from 0.81250\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0842 - acc: 0.9614 - val_loss: 0.4664 - val_acc: 0.8125\n",
      "Epoch 51/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0898 - acc: 0.9549\n",
      "Epoch 00051: val_acc did not improve from 0.81250\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0914 - acc: 0.9557 - val_loss: 0.4473 - val_acc: 0.8125\n",
      "Epoch 52/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0697 - acc: 0.9757\n",
      "Epoch 00052: val_acc did not improve from 0.81250\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0600 - acc: 0.9807 - val_loss: 0.4295 - val_acc: 0.8125\n",
      "Epoch 53/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.1008 - acc: 0.9722\n",
      "Epoch 00053: val_acc did not improve from 0.81250\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0827 - acc: 0.9780 - val_loss: 0.4146 - val_acc: 0.8125\n",
      "Epoch 54/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0666 - acc: 0.9826\n",
      "Epoch 00054: val_acc did not improve from 0.81250\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0606 - acc: 0.9844 - val_loss: 0.3969 - val_acc: 0.8125\n",
      "Epoch 55/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0825 - acc: 0.9700\n",
      "Epoch 00055: val_acc did not improve from 0.81250\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0711 - acc: 0.9780 - val_loss: 0.3842 - val_acc: 0.8125\n",
      "Epoch 56/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0543 - acc: 0.9931\n",
      "Epoch 00056: val_acc did not improve from 0.81250\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0488 - acc: 0.9945 - val_loss: 0.3706 - val_acc: 0.8125\n",
      "Epoch 57/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0607 - acc: 0.9850\n",
      "Epoch 00057: val_acc did not improve from 0.81250\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0595 - acc: 0.9890 - val_loss: 0.3574 - val_acc: 0.8125\n",
      "Epoch 58/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0755 - acc: 0.9775\n",
      "Epoch 00058: val_acc did not improve from 0.81250\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0654 - acc: 0.9835 - val_loss: 0.3460 - val_acc: 0.8125\n",
      "Epoch 59/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0511 - acc: 0.9888\n",
      "Epoch 00059: val_acc did not improve from 0.81250\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0577 - acc: 0.9862 - val_loss: 0.3356 - val_acc: 0.8125\n",
      "Epoch 60/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0644 - acc: 0.9850\n",
      "Epoch 00060: val_acc did not improve from 0.81250\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0719 - acc: 0.9780 - val_loss: 0.3263 - val_acc: 0.8125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0608 - acc: 0.9775\n",
      "Epoch 00061: val_acc improved from 0.81250 to 0.82292, saving model to transferlearning_weights.hdf5\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0598 - acc: 0.9807 - val_loss: 0.3170 - val_acc: 0.8229\n",
      "Epoch 62/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0536 - acc: 0.9850\n",
      "Epoch 00062: val_acc improved from 0.82292 to 0.83333, saving model to transferlearning_weights.hdf5\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0529 - acc: 0.9835 - val_loss: 0.3080 - val_acc: 0.8333\n",
      "Epoch 63/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0802 - acc: 0.9757\n",
      "Epoch 00063: val_acc did not improve from 0.83333\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0739 - acc: 0.9818 - val_loss: 0.2987 - val_acc: 0.8333\n",
      "Epoch 64/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0651 - acc: 0.9792\n",
      "Epoch 00064: val_acc did not improve from 0.83333\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0718 - acc: 0.9792 - val_loss: 0.2904 - val_acc: 0.8333\n",
      "Epoch 65/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.1008 - acc: 0.9583\n",
      "Epoch 00065: val_acc did not improve from 0.83333\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0839 - acc: 0.9669 - val_loss: 0.2837 - val_acc: 0.8333\n",
      "Epoch 66/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0598 - acc: 0.9925\n",
      "Epoch 00066: val_acc did not improve from 0.83333\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0680 - acc: 0.9862 - val_loss: 0.2776 - val_acc: 0.8333\n",
      "Epoch 67/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0749 - acc: 0.9722\n",
      "Epoch 00067: val_acc improved from 0.83333 to 0.84375, saving model to transferlearning_weights.hdf5\n",
      "4/4 [==============================] - 18s 4s/step - loss: 0.0811 - acc: 0.9661 - val_loss: 0.2699 - val_acc: 0.8438\n",
      "Epoch 68/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0768 - acc: 0.9653\n",
      "Epoch 00068: val_acc improved from 0.84375 to 0.85417, saving model to transferlearning_weights.hdf5\n",
      "4/4 [==============================] - 18s 4s/step - loss: 0.0712 - acc: 0.9688 - val_loss: 0.2632 - val_acc: 0.8542\n",
      "Epoch 69/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0367 - acc: 0.9925\n",
      "Epoch 00069: val_acc did not improve from 0.85417\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0433 - acc: 0.9835 - val_loss: 0.2567 - val_acc: 0.8542\n",
      "Epoch 70/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0788 - acc: 0.9663\n",
      "Epoch 00070: val_acc did not improve from 0.85417\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0698 - acc: 0.9752 - val_loss: 0.2523 - val_acc: 0.8542\n",
      "Epoch 71/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0561 - acc: 0.9850\n",
      "Epoch 00071: val_acc did not improve from 0.85417\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0604 - acc: 0.9780 - val_loss: 0.2476 - val_acc: 0.8542\n",
      "Epoch 72/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0454 - acc: 0.9963\n",
      "Epoch 00072: val_acc did not improve from 0.85417\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0462 - acc: 0.9972 - val_loss: 0.2419 - val_acc: 0.8542\n",
      "Epoch 73/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0598 - acc: 0.9826\n",
      "Epoch 00073: val_acc did not improve from 0.85417\n",
      "\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0500 - acc: 0.9862 - val_loss: 0.2366 - val_acc: 0.8542\n",
      "Epoch 74/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0802 - acc: 0.9722\n",
      "Epoch 00074: val_acc did not improve from 0.85417\n",
      "4/4 [==============================] - 18s 4s/step - loss: 0.0707 - acc: 0.9792 - val_loss: 0.2313 - val_acc: 0.8542\n",
      "Epoch 75/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0443 - acc: 0.9925\n",
      "Epoch 00075: val_acc improved from 0.85417 to 0.86458, saving model to transferlearning_weights.hdf5\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0437 - acc: 0.9917 - val_loss: 0.2275 - val_acc: 0.8646\n",
      "Epoch 76/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0418 - acc: 0.9965\n",
      "Epoch 00076: val_acc did not improve from 0.86458\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0378 - acc: 0.9974 - val_loss: 0.2233 - val_acc: 0.8646\n",
      "Epoch 77/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0494 - acc: 0.9888\n",
      "Epoch 00077: val_acc did not improve from 0.86458\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0623 - acc: 0.9807 - val_loss: 0.2200 - val_acc: 0.8646\n",
      "Epoch 78/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0868 - acc: 0.9722\n",
      "Epoch 00078: val_acc did not improve from 0.86458\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0711 - acc: 0.9780 - val_loss: 0.2181 - val_acc: 0.8646\n",
      "Epoch 79/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0770 - acc: 0.9618\n",
      "Epoch 00079: val_acc did not improve from 0.86458\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0726 - acc: 0.9714 - val_loss: 0.2144 - val_acc: 0.8646\n",
      "Epoch 80/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0490 - acc: 0.9925\n",
      "Epoch 00080: val_acc did not improve from 0.86458\n",
      "\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0440 - acc: 0.9945 - val_loss: 0.2115 - val_acc: 0.8646\n",
      "Epoch 81/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0390 - acc: 0.9925\n",
      "Epoch 00081: val_acc did not improve from 0.86458\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0489 - acc: 0.9835 - val_loss: 0.2086 - val_acc: 0.8646\n",
      "Epoch 82/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0646 - acc: 0.9813\n",
      "Epoch 00082: val_acc did not improve from 0.86458\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0577 - acc: 0.9862 - val_loss: 0.2067 - val_acc: 0.8646\n",
      "Epoch 83/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0713 - acc: 0.9792\n",
      "Epoch 00083: val_acc did not improve from 0.86458\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0648 - acc: 0.9835 - val_loss: 0.2046 - val_acc: 0.8646\n",
      "Epoch 84/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0432 - acc: 0.9925\n",
      "Epoch 00084: val_acc improved from 0.86458 to 0.87500, saving model to transferlearning_weights.hdf5\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0682 - acc: 0.9862 - val_loss: 0.2020 - val_acc: 0.8750\n",
      "Epoch 85/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0405 - acc: 0.9963\n",
      "Epoch 00085: val_acc improved from 0.87500 to 0.89583, saving model to transferlearning_weights.hdf5\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0505 - acc: 0.9917 - val_loss: 0.1993 - val_acc: 0.8958\n",
      "Epoch 86/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0942 - acc: 0.9688\n",
      "Epoch 00086: val_acc did not improve from 0.89583\n",
      "4/4 [==============================] - 18s 4s/step - loss: 0.0949 - acc: 0.9740 - val_loss: 0.1968 - val_acc: 0.8958\n",
      "Epoch 87/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0730 - acc: 0.9792\n",
      "Epoch 00087: val_acc did not improve from 0.89583\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0630 - acc: 0.9835 - val_loss: 0.1950 - val_acc: 0.8958\n",
      "Epoch 88/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0426 - acc: 0.9931\n",
      "Epoch 00088: val_acc did not improve from 0.89583\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0443 - acc: 0.9945 - val_loss: 0.1933 - val_acc: 0.8958\n",
      "Epoch 89/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0478 - acc: 0.9850\n",
      "Epoch 00089: val_acc did not improve from 0.89583\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0549 - acc: 0.9835 - val_loss: 0.1921 - val_acc: 0.8958\n",
      "Epoch 90/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0687 - acc: 0.9700\n",
      "Epoch 00090: val_acc did not improve from 0.89583\n",
      "\n",
      "Epoch 00090: ReduceLROnPlateau reducing learning rate to 1.0000001044244145e-13.\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0722 - acc: 0.9697 - val_loss: 0.1902 - val_acc: 0.8958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0832 - acc: 0.9700\n",
      "Epoch 00091: val_acc did not improve from 0.89583\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0789 - acc: 0.9752 - val_loss: 0.1886 - val_acc: 0.8958\n",
      "Epoch 92/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0477 - acc: 0.9813\n",
      "Epoch 00092: val_acc did not improve from 0.89583\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0630 - acc: 0.9752 - val_loss: 0.1877 - val_acc: 0.8958\n",
      "Epoch 93/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0697 - acc: 0.9792\n",
      "Epoch 00093: val_acc did not improve from 0.89583\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0634 - acc: 0.9835 - val_loss: 0.1861 - val_acc: 0.8958\n",
      "Epoch 94/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0810 - acc: 0.9588\n",
      "Epoch 00094: val_acc did not improve from 0.89583\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0883 - acc: 0.9642 - val_loss: 0.1851 - val_acc: 0.8958\n",
      "Epoch 95/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0737 - acc: 0.9738\n",
      "Epoch 00095: val_acc did not improve from 0.89583\n",
      "\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 1.0000001179769417e-14.\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0637 - acc: 0.9807 - val_loss: 0.1841 - val_acc: 0.8958\n",
      "Epoch 96/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0668 - acc: 0.9775\n",
      "Epoch 00096: val_acc did not improve from 0.89583\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0695 - acc: 0.9780 - val_loss: 0.1831 - val_acc: 0.8958\n",
      "Epoch 97/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0459 - acc: 0.9850\n",
      "Epoch 00097: val_acc did not improve from 0.89583\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0444 - acc: 0.9890 - val_loss: 0.1816 - val_acc: 0.8958\n",
      "Epoch 98/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0571 - acc: 0.9896\n",
      "Epoch 00098: val_acc did not improve from 0.89583\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0485 - acc: 0.9917 - val_loss: 0.1804 - val_acc: 0.8958\n",
      "Epoch 99/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0545 - acc: 0.9850\n",
      "Epoch 00099: val_acc did not improve from 0.89583\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0678 - acc: 0.9725 - val_loss: 0.1800 - val_acc: 0.8958\n",
      "Epoch 100/100\n",
      "3/4 [=====================>........] - ETA: 3s - loss: 0.0643 - acc: 0.9775\n",
      "Epoch 00100: val_acc did not improve from 0.89583\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 1.0000001518582595e-15.\n",
      "4/4 [==============================] - 17s 4s/step - loss: 0.0647 - acc: 0.9780 - val_loss: 0.1788 - val_acc: 0.8958\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "                              data_aug,\n",
    "                              steps_per_epoch=len(trainX)// batch_size, # parte inteira da divisão\n",
    "                              validation_data=(testX, testY),\n",
    "                              validation_steps=len(testX) // batch_size,# parte inteira da divisão\n",
    "                              callbacks=callbacks,\n",
    "                              epochs=epoch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANALISANDO DADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gerando matriz de confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "pred = model.predict(testX)\n",
    "pred = np.argmax(pred,axis = 1) \n",
    "y_true = np.argmax(testY,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.8462\n",
      "Sensitividade: 0.8333\n",
      "Especificidade: 0.9231\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATkAAAE9CAYAAABwcBXnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAUAElEQVR4nO3de5hVBbnH8d8LIwcEBE4Q5kBHBhBjlMSBkoyCFJR7+OBBNIs08CilqHk9mZcueCuPHT0ZmscyLoqXRyEVy2OYiHIzQBgRBI0ZUVRMkFJxfM8fs8CBmGEzs9cs5p3v53nmYe+1L+vd++H5Pmvty9rm7gKAqJpkPQAApInIAQiNyAEIjcgBCI3IAQiNyAEIrSDrAapq0ry1N2nZIesxGoXDO7XNeoRGoWkTy3qERmHDX1/V5rff2uOTvX9FrmUHtRpyTdZjNAqzrh+d9QiNQtuWB2Q9QqNw4oB+1V7G7iqA0IgcgNCIHIDQiByA0IgcgNCIHIDQiByA0IgcgNCIHIDQiByA0IgcgNCIHIDQiByA0IgcgNCIHIDQiByA0IgcgNCIHIDQiByA0IgcgNCIHIDQiByA0IgcgNCIHIDQiByA0IgcgNCIHIDQiByA0IgcgNCIHIDQiByA0IgcgNCIHIDQiByA0IgcgNCIHIDQiByA0IgcgNCIHIDQiNw+uGXCMVpz6xg9M2X4zmVtWzbTg5ccpyU3jtSDlxynNgc2y3DCeDaWl2n8mCEaPqBEIwb20d133Jr1SGGdP2mijuzWSQP79c56lLxKNXJmdqKZrTaztWZ2aZrrqg/Tn1qnMTf83y7Lzh9RrHmrXlfJ9x/WvFWv6/wRxRlNF1NBQYEuvnKK5vxpiWbOflLT77pda18qzXqskMaeerqm3Tc76zHyLrXImVlTSbdKGiKpp6RxZtYzrfXVh2dWb9I7732wy7KhJZ0148/rJEkz/rxOw/p0zmK0sDp0PFg9jzxKktSyVWsVde+hTa9vzHiqmI45tr/atWuX9Rh5l+aW3BckrXX3de7+oaSZkkaluL5MfPqg5nrjb/+QJL3xt3/o0wc1z3iiuMo3vKrSF5apV+8+WY+CBiTNyBVK2lDlfFmybBdmNtHMFpvZ4o/f35LiOPXD5VmPENK2be/pvAmn6bKrr1Or1gdlPQ4akMzfeHD3qe7ex937NGne8P7zbtryvjq2bSFJ6ti2hd7c8sFeboF9tX37dk2ecJqGjx6rQUPD7QwgZWlGrlxS1ReoOiXLQnl0aZnG9S+SJI3rX6RHlmzYyy2wL9xdV1x4joq69dD4s76X9ThogNKM3CJJ3c2si5k1k3SKpIdTXF/q7pj0ZT1+1Ynq/pmDtPIXo3X6V7vqptkvaOARB2vJjSM1oPhg3TR7ZdZjhrJ00QI9fP8MPffMPI0e1E+jB/XTvCfmZj1WSGefebpGDP6qXl7zkkp6Fmn6b/8365HywtzTew3JzIZK+i9JTSXd6e4/qen6BZ8q8lZDrkltHnxiwfWjsx6hUWjb8oCsR2gUThzQT8ueX2J7uqwgzRW7+yOSHklzHQBQk8zfeACANBE5AKEROQChETkAoRE5AKEROQChETkAoRE5AKEROQChETkAoRE5AKEROQChETkAoRE5AKEROQChETkAoRE5AKEROQChETkAoRE5AKEROQChETkAoRE5AKEROQChETkAoRE5AKEROQChETkAoRE5AKEROQChETkAoRE5AKEROQChETkAoRE5AKEROQChETkAoRE5AKEROQChFWQ9QFXFn22nx27996zHaBSKBlyQ9QiNwjuLbsl6hEahoIlVexlbcgBCI3IAQiNyAEIjcgBCI3IAQiNyAEIjcgBCI3IAQiNyAEIjcgBCI3IAQiNyAEIjcgBCI3IAQiNyAEIjcgBCI3IAQiNyAEIjcgBCI3IAQiNyAEIjcgBCI3IAQqv2d1fNbKsk33E2+deT0+7uB6U8GwDUWbWRc/fW9TkIAKQhp91VM/uymX07Od3ezLqkOxYA5MdeI2dmV0q6RNJlyaJmkn6X5lAAkC+5bMmNljRS0jZJcvfXJLErC6BByCVyH7q7K3kTwsxapjsSAORPLpG718x+JamtmU2Q9EdJt6c7FgDkR7Xvru7g7jea2SBJWyQdJumH7v6H1CcDgDzYa+QSKyS1UOUu64r0xgGA/Mrl3dXvSFoo6SRJYyQ9a2ZnpD0YAORDLltyF0nq7e5vS5KZfUrSM5LuTHMwAMiHXN54eFvS1irntybLAGC/V9N3Vy9ITq6V9JyZPaTK1+RGSVpeD7MBQJ3VtLu64wO/Lyd/OzyU3jgAkF81fUH/6vocBADSsNc3Hsysg6SLJRVLar5jubt/LcW5ACAvcnnjYZqkFyV1kXS1pFckLUpxJgDIm1wi9yl3/7Wk7e4+z93PkNTot+LOnzRRR3brpIH9emc9Sji3XXmaXn1iihbPunznsp9O/rr+8sAPtPCey3TPzyaoTasWGU4Y1+NzH1Ov4h4qPrybbrj+2qzHyYtcIrc9+XejmQ0zs96S/nVvNzKzO81sk5m9UKcJ91NjTz1d0+6bnfUYId09+1mNmnTrLsueePZFlZz8U31h7BSteXWTLjpjcEbTxVVRUaHJ507SQ7Mf1fPLV2nWzBkqXbUq67HqLJfI/djM2ki6UNL3Jd0h6fwcbneXpBNrP9r+7Zhj+6tdu3ZZjxHS/KUva/O7f99l2RPPvqiKio8lSQtXrFdhx7ZZjBbaooUL1bVrN3UpKlKzZs108thTNGd2w/8wRS5f0J+TnHxX0sBc79jdnzKzQ2s3FlC9b47qp/seX5r1GOG89lq5OnXqvPN8YWEnLVz4XIYT5UdNHwb+b33yQzb/xN3PTWUioAYXn3mCKio+1sxHeO8LualpS25xfQxgZhMlTZSkws6frY9VooH6xogvauhXjtCQs36R9SghHXJIocrKNuw8X15epsLCwgwnyo+aPgz8m/oYwN2nSpoqSZ/vXVLtliMat0Ff+pwuGH+8Bn/nZv3j/e17vwH2WZ++fbV27Rq9sn69Diks1Kx7Zuquu6dnPVad5Xo8Oezm7DNP14Knn9Lmt99SSc8iXXjpFTr1m9/OeqwQfjNlvPqXdFf7tq209rEf6Ue3PaKLvj1Y/9KsQHN++V1J0sIVr+jcn8zMeNJYCgoKdNPNt2jEsBNUUVGhb40/Qz2Li7Meq86s8ucbUrhjsxmSBkhqL+kNSVcmn7er1ud7l/hjf1qQyjzYVdGAC/Z+JdTZO4tuyXqERuHYL/bRkiWLbU+XpbYl5+7j0rpvAMhVLkcGPszMntjxoV4z62VmP0h/NACou1w+DHy7Kn9YerskuftySaekORQA5EsukTvQ3RfutuyjNIYBgHzLJXJvmVlXffLj0mMkbUx1KgDIk1zeeJikys+xHW5m5ZLWS/pGqlMBQJ7k8t3VdZKON7OWkpq4+9a93QYA9he5HBn4h7udlyS5+zUpzQQAeZPL7uq2KqebSxouqTSdcQAgv3LZXf1Z1fNmdqOkualNBAB5lMu7q7s7UFKnfA8CAGnI5TW5FfrkuHJNJXWQxOtxABqEXF6TG17l9EeS3nB3PgwMoEGoMXJm1lTSXHc/vJ7mAYC8qvE1OXevkLTazDhkL4AGKZfd1XaSVprZQlX5OIm7j0xtKgDIk1wid0XqUwBASnKJ3FB3v6TqAjO7TtK8dEYCgPzJ5XNyg/awbEi+BwGANNT0u6tnSzpHUpGZLa9yUWtJ89MeDADyoabd1emSHpU0RdKlVZZvdffNqU4FAHlS0++uvivpXUn8IA2ABqs2310FgAaDyAEIjcgBCI3IAQiNyAEIjcgBCI3IAQiNyAEIjcgBCI3IAQiNyAEIjcgBCI3IAQiNyAEIjcgBCI3IAQiNyAEIjcgBCI3IAQgtl99drTcFTUztWjbLeoxGYenvr8t6hEah3dAbsx6hUfhgzRvVXsaWHIDQiByA0IgcgNCIHIDQiByA0IgcgNCIHIDQiByA0IgcgNCIHIDQiByA0IgcgNCIHIDQiByA0IgcgNCIHIDQiByA0IgcgNCIHIDQiByA0IgcgNCIHIDQiByA0IgcgNCIHIDQiByA0IgcgNCIHIDQiByA0IgcgNCIHIDQiByA0IgcgNCIHIDQiByA0IgcgNCIHIDQiByA0IgcgNCIHIDQiFwtPT73MfUq7qHiw7vphuuvzXqcsDaWl2n8mCEaPqBEIwb20d133Jr1SKHcdsEJevXec7R46vidy07qf5iWTB2vbY9dqKO7d8xuuDxJLXJm1tnMnjSzVWa20szOS2td9a2iokKTz52kh2Y/queXr9KsmTNUumpV1mOFVFBQoIuvnKI5f1qimbOf1PS7btfal0qzHiuMu/+wUqMuv2+XZStfeUunXPOQnl5RltFU+ZXmltxHki50956SjpE0ycx6pri+erNo4UJ17dpNXYqK1KxZM5089hTNmf1Q1mOF1KHjwep55FGSpJatWquoew9ten1jxlPFMX9FmTZvfX+XZas3bNaasncymij/Uoucu29096XJ6a2SSiUVprW++vTaa+Xq1KnzzvOFhZ1UXl6e4USNQ/mGV1X6wjL16t0n61HQgNTLa3Jmdqik3pKeq4/1IZ5t297TeRNO02VXX6dWrQ/Kehw0IKlHzsxaSbpf0mR337KHyyea2WIzW/zmW2+mPU5eHHJIocrKNuw8X15epsLCEBup+6Xt27dr8oTTNHz0WA0aOirrcdDApBo5MztAlYGb5u4P7Ok67j7V3fu4e58O7TukOU7e9OnbV2vXrtEr69frww8/1Kx7ZmrY8JFZjxWSu+uKC89RUbceGn/W97IeBw1QQVp3bGYm6deSSt3952mtJwsFBQW66eZbNGLYCaqoqNC3xp+hnsXFWY8V0tJFC/Tw/TN02OeKNXpQP0nS5Euv0lePOyHjyWL4zWXD1L9XZ7Vv00Jrp52lH909X+9sfV8/P+c4tW/TQg/8+CQtf3mTRl5+f9aj1pq5ezp3bPZlSX+WtELSx8niy939kepuU1LSx+c/tziVebCr9Zu2ZT1Co3D0+F9mPUKj8MGzN+vjLRtsT5eltiXn7k9L2uNKAaC+8I0HAKEROQChETkAoRE5AKEROQChETkAoRE5AKEROQChETkAoRE5AKEROQChETkAoRE5AKEROQChETkAoRE5AKEROQChETkAoRE5AKEROQChETkAoRE5AKEROQChETkAoRE5AKEROQChETkAoRE5AKEROQChETkAoRE5AKEROQChETkAoRE5AKEROQChETkAoRE5AKEROQChETkAoRE5AKGZu2c9w05m9qakV7OeYx+1l/RW1kM0AjzP9achPtf/5u4d9nTBfhW5hsjMFrt7n6zniI7nuf5Ee67ZXQUQGpEDEBqRq7upWQ/QSPA8159QzzWvyQEIjS05AKERuVoysxPNbLWZrTWzS7OeJyozu9PMNpnZC1nPEp2ZdTazJ81slZmtNLPzsp4pH9hdrQUzayrpJUmDJJVJWiRpnLuvynSwgMzsK5Lek/Rbdz8i63kiM7PPSPqMuy81s9aSlkj6ekP/f82WXO18QdJad1/n7h9KmilpVMYzheTuT0nanPUcjYG7b3T3pcnprZJKJRVmO1XdEbnaKZS0ocr5MgX4zwDsYGaHSuot6blsJ6k7IgdgF2bWStL9kia7+5as56krIlc75ZI6VznfKVkGNGhmdoAqAzfN3R/Iep58IHK1s0hSdzPrYmbNJJ0i6eGMZwLqxMxM0q8llbr7z7OeJ1+IXC24+0eSvitpripfnL3X3VdmO1VMZjZD0gJJPcyszMzOzHqmwI6VdLqkr5nZX5K/oVkPVVd8hARAaGzJAQiNyAEIjcgBCI3IAQiNyAEIjcghdWY2wMzmJKdH1nTUFjNra2bn1GIdV5nZ93Ndvtt17jKzMfuwrkM5KkrDQeRQa8nRWPaJuz/s7tfWcJW2kvY5ckB1iBz+SbKl8qKZTTOzUjO7z8wOTC57xcyuM7Olkk42s8FmtsDMlprZrOR7jzuOt/dicr2Tqtz3eDO7JTnd0cweNLNlyd+XJF0rqWvyQdQbkutdZGaLzGy5mV1d5b7+08xeMrOnJfXI4XFNSO5nmZndv+MxJY43s8XJ/Q1Prt/UzG6osu6z6vrcov4ROVSnh6T/cffPSdqiXbeu3nb3oyX9UdIPJB2fnF8s6QIzay7pdkkjJJVIOriadfxC0jx3/7ykoyWtlHSppJfd/Sh3v8jMBkvqrsrDWx0lqcTMvmJmJar8Ot1RkoZK6pvDY3rA3fsm6yuVVPXbE4cm6xgm6bbkMZwp6V1375vc/wQz65LDerAfKch6AOy3Nrj7/OT07ySdK+nG5Pw9yb/HSOopaX7l1x7VTJVfwTpc0np3XyNJZvY7SRP3sI6vSfqmJLl7haR3zazdbtcZnPw9n5xvpcrotZb0oLv/PVlHLt8dPsLMfqzKXeJWqvxa3g73uvvHktaY2brkMQyW1KvK63VtknW/lMO6sJ8gcqjO7t/3q3p+W/KvSfqDu4+rekUzOyqPc5ikKe7+q93WMbkW93WXKo90u8zMxksaUOWyPT1ek/Q9d68awx3HWkMDwe4qqvNZM+uXnD5V0tN7uM6zko41s26SZGYtzewwSS9KOtTMuibXG7eH20rSE5LOTm7b1MzaSNqqyq20HeZKOqPKa32FZvZpSU9J+rqZtUgO1T0ih8fUWtLG5HBCp+122clm1iSZuUjS6mTdZyfXl5kdZmYtc1gP9iNEDtVZLWmSmZVKaifpl7tfwd3flDRe0gwzW65kV9Xd31fl7unvkzceNlWzjvMkDTSzFar8PYGe7v62Knd/XzCzG9z9cUnTJS1IrnefpNbJYbrvkbRM0qOqPPzV3lyhyiPdzldliKv6q6SFyX39R/IY7pC0StLS5CMjvxJ7Pw0ORyHBP0l2x+bwwzGIgC05AKGxJQcgNLbkAIRG5ACERuQAhEbkAIRG5ACERuQAhPb/lpCOv1pjszsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_true, pred)\n",
    "total = sum(sum(cm))\n",
    "acc = (cm[0, 0] + cm[1, 1] + cm[2,2]) / total\n",
    "sensitivity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
    "specificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n",
    "\n",
    "print(\"Acurácia: {:.4f}\".format(acc))\n",
    "print(\"Sensitividade: {:.4f}\".format(sensitivity))\n",
    "print(\"Especificidade: {:.4f}\".format(specificity))\n",
    "\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "fig, ax = plot_confusion_matrix(conf_mat=cm ,  figsize=(5, 5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Detector COVID-19 automático 96,15% de Acurácia.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Também estamos obtendo 100% de sensibilidade e 92% de especificidade, o que implica que:\n",
    "\n",
    "- Sensibilidade, capacidade indentificar caso positivo de COVID-19 com o modelo é de 100%.\n",
    "\n",
    "\n",
    "- Especificidade, capacidade indentificar caso Não-Positivo de COVID-19 com o modelo é de 92,31%.\n",
    "\n",
    "\n",
    "- Como mostra nosso gráfico de histórico de treinamento, nossa rede não está adaptando demais, apesar de ter dados de treinamento limitado"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
